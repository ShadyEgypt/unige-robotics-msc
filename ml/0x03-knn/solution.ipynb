{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape and normalize the data\n",
    "train_X = train_X.reshape(train_X.shape[0], -1) / 255.0\n",
    "test_X = test_X.reshape(test_X.shape[0], -1) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classify(train_X, train_y, test_X, k):\n",
    "    \"\"\"\n",
    "    Classifies test set according to the k-Nearest Neighbors (kNN) rule.\n",
    "    \n",
    "    Parameters:\n",
    "        train_X (ndarray): Training set feature matrix\n",
    "        train_y (ndarray): Training set labels\n",
    "        test_X (ndarray): Test set feature matrix\n",
    "        k (int): Number of nearest neighbors to use for classification\n",
    "        \n",
    "    Returns:\n",
    "        test_predictions (ndarray): Predicted labels for the test set\n",
    "    \"\"\"\n",
    "\n",
    "    # Check that k > 0 and k <= cardinality of the training set\n",
    "    n = train_X.shape[0]\n",
    "    if k <= 0 or k > n:\n",
    "        raise ValueError(f\"k must be greater than 0 and less than or equal to {n}\")\n",
    "\n",
    "    # Check that the number of columns in test_X equals the number of columns in train_X\n",
    "    if train_X.shape[1] != test_X.shape[1]:\n",
    "        raise ValueError(\"Number of columns in test set must match the training set\")\n",
    "\n",
    "    # Perform kNN classification\n",
    "    test_predictions = []\n",
    "    for test_sample in test_X:\n",
    "        # Compute distances from test_sample to all training samples\n",
    "        distances = np.linalg.norm(train_X - test_sample, axis=1)\n",
    "        \n",
    "        # Get the indices of the k nearest neighbors\n",
    "        neighbor_indices = np.argsort(distances)[:k]\n",
    "        \n",
    "        # Get the labels of the k nearest neighbors\n",
    "        neighbor_labels = train_y[neighbor_indices]\n",
    "        \n",
    "        # Determine the most frequent label (mode) among the neighbors\n",
    "        predicted_label = mode(neighbor_labels).mode\n",
    "        if isinstance(predicted_label, np.ndarray):  # Ensure it's an array and take the first element if so\n",
    "            predicted_label = predicted_label[0]\n",
    "        \n",
    "        # Append the predicted label to the list\n",
    "        test_predictions.append(predicted_label)\n",
    "\n",
    "    return np.array(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error_rate(predictions, targets):\n",
    "    \"\"\"\n",
    "    Computes the error rate of predictions against the true targets.\n",
    "    \n",
    "    Parameters:\n",
    "        predictions (ndarray): Predicted labels\n",
    "        targets (ndarray): Actual labels\n",
    "        \n",
    "    Returns:\n",
    "        error_rate (float): Error rate calculated as number of errors divided by number of samples\n",
    "    \"\"\"\n",
    "    errors = np.sum(predictions != targets)\n",
    "    error_rate = errors / len(targets)\n",
    "    return error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "\n",
    "# Classify the test set\n",
    "predictions = knn_classify(train_X, train_y, test_X, k)\n",
    "\n",
    "# Check if there is an optional target column in test set (i.e., test_y provided)\n",
    "error_rate = compute_error_rate(predictions, test_y)\n",
    "print(f\"Error Rate: {error_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
